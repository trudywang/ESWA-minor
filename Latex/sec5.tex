\section{Experiments }
\label{sec:exp}

We used three data sets Aalborg\footnote{http://www.dbxr.org/experimental-guidelines/}, Beijing\footnote{http://arxiv.org/abs/cs/04100001}, and Singapore \citep{Song2014PRESS} in our experiments. Each data set consists of a weighted road network and a query log. Since the numbers of queries in the Aalborg and Beijing query logs are relatively small, we enlarge the query logs.
The query log of each data set is divided into two parts; one half is the training set and the other half is the test set. Training sets act as historical logs while test sets act as future queries. The frequency statistics are extracted from the training set, and the cache is filled based on benefit values.
Table \ref{tab:datasetinfo} summarizes the information on the data sets. Columns ``Size of training set'' and ``Size of test set'' indicate the number of queries in the training set and test set, respectively. We assume that the query trend on training sets and test sets are similar, and the statistic information from training sets can predict future queries to some extent.

 \begin{table}[htbp]
 \caption{Information of data sets.}
 \centering
 \label{tab:datasetinfo}
{
 \begin{tabular}{c|c|c|c|c}
 \hline
  Data set   & No. of nodes & No. of edges & Size of training set & Size of test set\\
  \hline
  Aalborg    & 129k         & 137k         &23,720                            & 23,720\\
  \hline
   Beijing   & 76k          &85k           &64,640                            & 64,640\\
  \hline
   Singapore & 20,801       &55,892        &150,000                           & 150,000\\
   \hline
 \end{tabular}
}
\end{table}

We generated 50 instances based on each data set; one half of the instances increase weights of edges and the other half decrease weights. The increased and decreased edges must a relatively high impact on the response efficiency.
To meet the criteria, we firstly generated instances with weights increased, then the decreased instances. Hereafter, we explain the process of generating instances for Aalborg. For the other data sets, the process is totally the same.

The cache was initialized based on the road network and training set of Aalborg.
For each path in the cache, two consecutive nodes of the path forms an edge. We sorted all edges formed by the cached paths based on edges' frequencies of appearance. The 25 edges with the highest frequencies were marked.
The road network in Aalborg act as the road network before the weight of one edge is increased (original network). Each time, we selected one marked edge $e$ and increased $w_e$ by 10 times, resulting in a changed road network (new network). The 25 edges were sequentially increased and 25 corresponding instances with weights increased were obtained.
For the instances of weights decreased, new networks of increased instances act as the original networks. When $w_e$ of marked edges recovered to their weights recorded in Aalborg, we yielded instances with decreased weights.


All the code was implemented in GNU C++. The experiments were run on a PC with an Intel i7 Quad Core CPU clocked at 3.10 GHz.

\subsection{Effect of Cache Structure}
\label{sec:effect-cache-structure}
We use a bitmap-based structure in Section~\ref{sec:Cache Structure} to facilitate the cache on answering users' queries.
To have an impression of how the bitmap structure works, we compare it with a benchmark structure, which only records shortest paths in a path array.
Queries are answered by scanning the array.
The benchmark structure is called a basic cache.

For each data set, the cache is firstly initialized based on the largest benefit values of paths in the query log. Queries in the test sets arrive one by one and the total response time by two cache structure is displayed in Figure~\ref{fig:time-cache-structure}. We can see that the time performance of bitmap structure is much better than that of basic structure. The response time of bitmap is only 0.7ms when the cache size is 9MB for the Aalborg data set, while it costs 205ms for the basic structure. We can get consistent results on Beijing and Singapore data sets.
Moreover, the response time is almost constant with the increase of cache size for the bitmap structure.
\begin{figure}[htbp]
\centering
    \subfigure[{\footnotesize Aalborg}]
   {\includegraphics
   [height=3.5cm]{figure/construct-cache-time-aal.eps}}
   \subfigure[{\footnotesize Beijing}]
   {\includegraphics [height=3.5cm]{figure/construct-cache-time-beijing.eps}}
   \subfigure[{\footnotesize Singapore}]
   {\includegraphics [height=3.5cm]{figure/construct-cache-time-singapore.eps}}
 \caption{Response time of cache structures.}
 \label{fig:time-cache-structure}
\end{figure}


\subsection{Efficiency of Detecting Affected Paths in the Cache}
\label{ssec:efficiency-detecting}
Detecting affected paths in a cache is an important step before refreshing a cache. To demonstrate the performance of our algorithms, a naive method (NM) is used as a benchmark method. Due to the size of graph, NM only re-computes new shortest paths for all pairs of nodes in the cache and compares them with the original ones. If the two shortest paths for a pair of nodes are different, then an affected path is detected.
We test our three affected paths detecting algorithms NEA, ONE, INE and NM on Aalborg, Beijing and Singapore data sets and the detection time of the four detection methods is regarded as the performance indicator.

The experimental result on each data set is the average of 25 instances where $w_e$ decreases.
As seen from Figure~\ref{fig:comparison-detecttime}, all of our algorithms have a better performance than NM.
For example, in the Aalborg data set, when the cache size is 9MB, the algorithm INE achieves the best time performance and its detection time is only 131ms, while NM costs 28.67s. Meanwhile, we observe that INE is slightly superior to ONE and ONE is superior to NEA. This is consistent with our expectation.
\begin{figure}[htbp]
\centering
   \subfigure[{\footnotesize Aalborg}]
   {\includegraphics
   [height=3.5cm]{figure/A-size-time.eps}}
   \subfigure[{\footnotesize Beijing}]
   {\includegraphics [height=3.5cm]{figure/A-size-time-beijing.eps}}
   \subfigure[{\footnotesize Singapore}]
   {\includegraphics [height=3.5cm]{figure/singapore-detectaffect-time.eps}}
 \caption{Performance of affected path detection methods.}
 \label{fig:comparison-detecttime}
\end{figure}

%In addition, we can see the detection time is generally proportional to the size of graph.
%Aalborg has minimal time cost, Singapore has mediate time cost, and Beijing has the most time cost. The graph of Aalborg is sparse, the graph of Singapore is intermediate, and Beijing is dense. The denser a graph is, the more time it will cost because the algorithms check more paths in a dense graph to yield affected paths.

\subsection{Performance of Refreshment Strategies}
\label{ssec:overhead-strategy}

Figure~\ref{fig:comparison-hit} shows the hit-ratios of four refreshment strategies under different scales of caches.
We sum up hit ratio of 50 instances for ease of read, since the differences among strategies are tiny.
We can observe that RWC and RLB achieve the highest hit ratio. The reason is that even though RWC and RLB are based on different logics to update caches, the paths which are loaded into the cache are actually the same.
The hit ratios of RHF and RRWS are similar and a little bit worse than the former two. This result is consistent with the logics of methods, since RHF and RRWS are not fully based on large benefit values.
From the perspective of cache size, when the cache size increases, the cache will hold more paths. The cache will answer more queries, subsequently, the hit ratio increases.


\begin{figure}[htbp]
\centering
   \subfigure[{\footnotesize Aalborg}]
   {\includegraphics
   [height=3.5cm]{figure/aalborgHitVsCacheSize.eps}}
   \subfigure[{\footnotesize Beijing}]
   {\includegraphics [height=3.5cm]{figure/beijingHitVsCacheSize.eps}}
   \subfigure[{\footnotesize Singapore}]
   {\includegraphics [height=3.5cm]{figure/singaporeHitVsCacheSize.eps}}
 \caption{Hit ratios of refreshment strategies.}
 \label{fig:comparison-hit}
\end{figure}


Next we test the refreshment time of these four replacement strategies along with various cache sizes on three data sets.
The refreshment time includes three parts: the time of detecting affected paths, the time of computing shortest paths by the server, and the time of selecting new paths into the cache. For RWC, the time of detecting affected paths is zero.
The experimental result (rf. Figure~\ref{fig:comparison-overall-time}) on each data set is the average of 50 instances.
The performance on three data sets is consistent; each method displays similar trends on three data sets.
RWC spends the most refreshment time, and the time increases as the cache size increases. It can be predicted that the disadvantage of RWC in refreshment time will amplify more if more shortest paths are queried, since RWC takes a lot of time to computing shortest paths every time the cache is emptied.
RLB, RHF, and RRWS spend similar time.
Precisely, RLB has the shortest refreshment time.
This is consistent with our analysis in Section~\ref{sec:strategies}.
 \begin{figure}[htbp]
\centering
   \subfigure[{\footnotesize Aalborg}]
   {\includegraphics
   [height=3.5cm]{figure/A-size-method-time.eps}}
   \subfigure[{\footnotesize Beijing}]
   {\includegraphics [height=3.5cm]{figure/A-size-method-time-beijing.eps}}
   \subfigure[{\footnotesize Singapore}]
   {\includegraphics [height=3.5cm]{figure/SinggporeCache-size-time.eps}}
   \caption{Refreshment time of refreshment strategies.}
   \label{fig:comparison-overall-time}
\end{figure}

From the above experiments, we can see that RLB has the best running time and hit ratio. Hence, in the real applications, RLB is suggested to be used.



